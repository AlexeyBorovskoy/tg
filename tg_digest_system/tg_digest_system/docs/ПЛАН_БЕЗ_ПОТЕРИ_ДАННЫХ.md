# План интеграции без потери данных

Корень проекта: **analysis-methodology** (вся история и данные).

## Где что лежит

### 1. Файлы (источник правды, не трогаем)

| Что | Где в проекте |
|-----|----------------|
| Каналы (список, промпты, получатели) | `config/channels.json`, `deploy/channels.yandex.json`, `tg_digest_system/tg_digest_system/config/channels.json` |
| Тексты промптов (дайджест, consolidated) | `tg_digest_system/tg_digest_system/prompts/*.md` (digest_management.md, consolidated_engineering.md и др.) |
| Секреты (не в git) | `.env`, `tg_digest_system/tg_digest_system/docker/secrets.env` на каждой машине |

Воркер уже умеет:
- брать каналы из **файла** (CONFIG_FILE → channels.json) и из **БД** (web_channels), объединяя их;
- брать текст промпта: сначала из БД (channel_prompts / web_channels), при отсутствии — из **файла** по `channel.prompt_file` (prompts/*.md).

Итого: **промпты и конфиг каналов в файлах не теряются**, если не перезаписывать эти файлы и не менять пути (CONFIG_FILE, PROMPTS_DIR).

### 2. Базы данных на ВМ 158.160.19.253 (ripas)

| База | Содержимое | Действия |
|------|------------|----------|
| **rag** | tg.messages (сообщения из Telegram), возможно tg.media, rpt.* | **Не удалять, не очищать.** Только добавлять колонки/таблицы нашими миграциями (ADD COLUMN IF NOT EXISTS, CREATE TABLE IF NOT EXISTS). |
| **tg_digest** | Пока без prompt_library, web_channels=0 | Либо применять миграции сюда и вести веб-данные (users, web_channels) здесь; либо использовать одну БД (rag) для всего — см. ниже. |

Миграции в `db/migrations/` (001–007) **не делают** DROP TABLE и не удаляют данные: только CREATE TABLE IF NOT EXISTS, ADD COLUMN IF NOT EXISTS, триггеры. Исключение: 007 делает `ALTER TABLE users ALTER COLUMN telegram_id DROP NOT NULL` (разрешаем NULL для OAuth).

### 3. Выбор БД для нашего сервиса

- **Вариант A: одна БД — rag**  
  Все данные (сообщения + веб: users, web_channels, channel_prompts, prompt_library, user_identities, audit_log) в **rag**.  
  На 158.160.19.253: применить к rag сначала базовую схему (если чего-то не хватает), затем миграции 001–007. Web и воркер подключать к rag (PGHOST, PGDATABASE=rag, PGUSER, PGPASSWORD).  
  Плюс: один источник правды, сообщения уже там. Минус: нужно аккуратно применить миграции к существующей БД (лучше бэкап).

- **Вариант B: две БД — rag + tg_digest**  
  **rag** — только сообщения (tg.messages и т.д.), не трогаем или только добавляем колонки при необходимости.  
  **tg_digest** — пользователи, каналы веб-интерфейса, промпты в БД, OAuth, аудит. К tg_digest применяем миграции 001–007. Web и воркер подключать к **tg_digest**; воркер при этом не видит сообщения из rag (если воркер пишет/читает только tg_digest).  
  Плюс: разделение. Минус: если сообщения реально лежат в rag, воркеру нужен доступ к rag для чтения сообщений — тогда либо воркер к rag, либо перенос сообщений в tg_digest (миграция данных, без удаления из rag до проверки).

Рекомендация: если **сообщения (tg.messages) уже в rag** и другой сервис их использует — оставить сообщения в rag. Тогда либо поднимаем наш сервис (web + воркер) с **PGDATABASE=rag** и применяем к rag только миграции 001–007 (добавляют таблицы users, web_channels, channel_prompts, prompt_library, user_identities, audit_log и колонки user_id и т.д., без удаления данных). Либо поднимаем с **PGDATABASE=tg_digest**, применяем миграции к tg_digest, а для сообщений оставляем отдельный доступ/скрипты к rag до переноса (если решите переносить).

Ниже описан **вариант «всё в rag»** без потери данных.

### 4. Полная история чатов и OCR / ChatGPT

- **Обычный цикл воркера (после первого запуска по каналу):**  
  Воркер берёт `last_msg_id` из `rpt.report_state` и запрашивает у Telegram **только новые сообщения** (id > last_msg_id). Сохраняет их в БД, медиа — с OCR. В дайджест и в ChatGPT отправляется **только этот новый диапазон**. То есть **вся история чатов не выкачивается и не прогоняется через ChatGPT/OCR при каждом запуске** — только инкремент.

- **Первый запуск по каналу (канал только что добавлен):**  
  В `rpt.report_state` ещё нет записи → `last_msg_id = 0`. Тогда запрос к Telegram с `min_id=0` возвращает **все сообщения канала**. То есть **при первом запуске после добавления канала** действительно выкачивается **вся история**, сохраняется в БД, медиа проходят OCR, и **весь этот диапазон** отправляется в ChatGPT для дайджеста. Дальше — только инкремент.

Итого: полная история выкачивается и прогоняется через OCR и ChatGPT **только один раз** — при первом запуске воркера по новому каналу. Дальше обрабатываются только новые сообщения.

---

## План шагов (без потери данных)

### Этап 1. Резервное копирование (обязательно)

На 158.160.19.253 под пользователем ripas (или postgres):

```bash
# Бэкап rag (все данные)
pg_dump -h localhost -U postgres -d rag -F c -f /home/ripas/backup_rag_$(date +%Y%m%d_%H%M%S).dump

# При двух БД — бэкап tg_digest
pg_dump -h localhost -U postgres -d tg_digest -F c -f /home/ripas/backup_tg_digest_$(date +%Y%m%d_%H%M%S).dump
```

Не удалять дампы до успешной проверки работы сервиса.

### Этап 2. Применение миграций к выбранной БД

Если выбрана **одна БД rag** (сообщения уже там):

1. Скопировать на ВМ каталог с миграциями:  
   `tg_digest_system/tg_digest_system/db/` (schema.sql и migrations/).
2. На ВМ от имени пользователя с правами на создание объектов в rag (например postgres):
   - при необходимости сначала применить `schema.sql` (только создаёт недостающие схемы/таблицы, IF NOT EXISTS);
   - затем по порядку: 001, 002, 003, 004, 005, 006, 007.

Команды пример (подставить путь к репо на ВМ):

```bash
cd /home/ripas/tg_digest_system/tg_digest_system  # или где лежит репо
sudo -u postgres psql -d rag -f db/schema.sql
for f in db/migrations/001_*.sql db/migrations/002_*.sql db/migrations/003_*.sql db/migrations/004_*.sql db/migrations/005_*.sql db/migrations/006_*.sql db/migrations/007_*.sql; do
  [ -f "$f" ] && sudo -u postgres psql -d rag -f "$f"
done
```

Если выбрана **отдельная БД tg_digest** для веб-части — те же команды, заменить `-d rag` на `-d tg_digest`. Данные в rag при этом не трогаем.

### Этап 3. Конфигурация сервиса на ВМ

- **.env / secrets.env** (в каталоге docker или в корне сервиса):
  - PGHOST=localhost (или 127.0.0.1)
  - PGPORT=5432
  - PGDATABASE=rag (или tg_digest — по выбору варианта)
  - PGUSER=… (пользователь с доступом к выбранной БД)
  - PGPASSWORD=…
  - Остальное: TG_*, OPENAI_*, CONFIG_FILE, PROMPTS_DIR, AUTH_OWN_ENABLED, BASE_URL, YANDEX_OAUTH_*, JWT_SECRET и т.д. — без перезаписи существующих секретов; добавлять только недостающее.

- **Файлы конфигурации каналов и промптов** не перезаписывать: оставить текущие `config/channels.json` (или deploy/channels.yandex.json) и `prompts/*.md`. CONFIG_FILE и PROMPTS_DIR указать на эти пути.

### Этап 3.1. Выгрузка промптов в БД (общий доступ)

Чтобы промпты из `prompts/*.md` были в БД и доступны всем (веб, воркер):

- **Вариант 1 — через веб (после запуска):** авторизоваться, вызвать `POST /api/prompt-library/sync`. Эндпоинт читает PROMPTS_DIR и заполняет/обновляет таблицу `prompt_library`.

- **Вариант 2 — однократный скрипт (до или после запуска веба):**
  ```bash
  cd tg_digest_system/tg_digest_system/scripts
  # secrets.env или переменные PGHOST, PGDATABASE, PGUSER, PGPASSWORD
  PROMPTS_DIR=../prompts python seed_prompt_library.py
  ```

После этого шаблоны из файлов будут в `prompt_library` и доступны при создании/редактировании каналов в вебе и воркеру.

### Этап 4. Запуск нашего сервиса (Docker или systemd)

- Использовать **существующую БД** (не поднимать свой контейнер postgres): в docker — `docker-compose.existing.yml`, PGHOST=host.docker.internal или IP хоста с ВМ, PGDATABASE=rag (или tg_digest), те же PGUSER/PGPASSWORD.
- Volumes: примонтировать каталог с репо (или хотя бы config + prompts), чтобы CONFIG_FILE и PROMPTS_DIR указывали на актуальные channels.json и prompts/*.md.
- После запуска проверить: вход по OAuth, страницы «Каналы» и «Промпты», воркер (один цикл без ошибок). Логи и аудит не удалять.

### Этап 5. Проверка целостности

- Убедиться, что в БД количество сообщений (tg.messages) и при необходимости других таблиц не уменьшилось.
- Убедиться, что дайджесты генерируются и промпты подставляются из файлов (и при наличии — из БД).

---

## Кратко

- **Данные в файлах** (channels.json, prompts/*.md): не перезаписывать; пути задавать через CONFIG_FILE и PROMPTS_DIR.
- **Данные в БД** (rag / tg_digest): не делать DROP/TRUNCATE; только добавлять схему и колонки нашими миграциями; перед применением — бэкап.
- **Секреты**: не затирать существующие .env/secrets.env на ВМ; дополнять только нужными переменными для web/OAuth/worker.
- После применения плана вся история и данные остаются в проекте (analysis-methodology) и в выбранной БД на 158.160.19.253.
